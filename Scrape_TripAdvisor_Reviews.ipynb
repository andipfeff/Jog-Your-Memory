{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d655d4f5",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec5521",
   "metadata": {},
   "source": [
    "# Load and clean Trip Advisor URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TA URLs data file into a Data Frame\n",
    "data_to_load = \"Resources/TripAdvisor_NatPark_Scraped_URLs.csv\"\n",
    "TA_URLs = pd.read_csv(data_to_load)\n",
    "TA_URLs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb85f06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data Frame to hold clean list of URLs\n",
    "Clean_URLs_df = TA_URLs.copy()\n",
    "Clean_URLs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed25fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Duplicates\n",
    "Clean_URLs_df = Clean_URLs_df.drop_duplicates()\n",
    "Clean_URLs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cf7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove URLs that belong to Hotels, Restaurants, Vacations, etc\n",
    "Clean_URLs_df = Clean_URLs_df[Clean_URLs_df['Direct_URL'].str.contains(\"tripadvisor.com/Attraction_Review\")==True]\n",
    "Clean_URLs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clean_URLs_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f5eddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a list out of the cleaned URLs df to use as a for loop ticker during scraping\n",
    "Clean_URLs_list = Clean_URLs_df['Direct_URL'].to_list()\n",
    "print(Clean_URLs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612aa452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to hold the scraped reviews\n",
    "TA_Reviews_List = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7840daa5",
   "metadata": {},
   "source": [
    "# Scrape TripAdvisor Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c9a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f27aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop the list of trails through search and grab the URL\n",
    "for x in Clean_URLs_list:\n",
    "    \n",
    "    # Visit the trip advisor site\n",
    "    browser.visit(x)\n",
    "    # Optional delay for loading the page\n",
    "    browser.is_element_present_by_css('div.list_text', wait_time=1)\n",
    "    \n",
    "    # Parse the HTML\n",
    "    html = browser.html\n",
    "    html_soup = soup(html, 'html.parser')\n",
    "    \n",
    "    # Grab page title\n",
    "    page_title = browser.title\n",
    "    \n",
    "    try:\n",
    "        # Create Trail Name Variable\n",
    "        Trail = html_soup.find('h1', class_='WlYyy cPsXC GeSzT').text\n",
    "    except:\n",
    "        Trail = \"could not scrape\"\n",
    "    \n",
    "    # Retrieve the parent divs for all reviews\n",
    "    reviews = html_soup.find_all('div', class_='ffbzW _c')\n",
    "    \n",
    "    # Loop through review card to get review data\n",
    "    for reviewcard in reviews:\n",
    "        # scrape the review title\n",
    "        title = reviewcard.find('div', class_='WlYyy cPsXC bLFSo cspKb dTqpp').text\n",
    "    \n",
    "        # scrape the review text\n",
    "        review = reviewcard.find('div', class_='WlYyy diXIH dDKKM').text\n",
    "        \n",
    "        # print review data\n",
    "        print('-----------------')\n",
    "        print(Trail)\n",
    "        print(title)\n",
    "    \n",
    "        # Create a dictionary\n",
    "        review_dict = {\n",
    "            'Page Title':page_title,\n",
    "            'Trail Name':Trail,\n",
    "            'Review Title': title,\n",
    "            'Review': review\n",
    "            }\n",
    "    \n",
    "        # Append data to trail_reviews list\n",
    "        TA_Reviews_List.append(review_dict)  \n",
    "    \n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea8fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews_df = pd.DataFrame(TA_Reviews_List, columns=['Page Title','Trail Name','Review Title', 'Review'])\n",
    "Reviews_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reviews_df.to_csv(r\"Resources/TripAdvisor_Reviews.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
